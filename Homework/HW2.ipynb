{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitpytorchcondacea95a9aa1ff4dccbaf1b76d59752e67",
   "display_name": "Python 3.9.2 64-bit ('pytorch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "473297526cef0b63cde6061c30fc5781ec0366ecb219ec17eb118d28b3bc0202"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Homework 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Reconstruct in PyTorch the first experiment in [Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0) with learning rule in eq.8 (gradient descent without momentum). Try to be as close as possible to the original protocol, except for what regards the learning rule.\n",
    "  - Read the paper, if you did not do it yet (don’t worry if you don’t understand the other experiments in detail)\n",
    "  - Create the data, the model and everything is needed (do not use dataloaders if you don’t know how yet how they work)\n",
    "  - Train the model\n",
    "  - Inspect the weights you obtained and check if they provide a solution to the problem\n",
    "  - Compare the solution to the solution reported in the paper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We will reproduce the experiment in Fig. 1 of the paper.\n",
    "We want to detect mirror symmetry in the input vectors. Since we have 6 nodes in the inputs units our vectors will have 6 elements each, which will be either $1$ or $0$, so we will have $2^6 = 64$ possible input vectors.\n",
    "Since we have two hidden units, we will have one layer with two nodes, both having the bias."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scripts.train_utils import AverageMeter\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate vectors\n",
    "X = torch.Tensor([item for item in product([0, 1], repeat=6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\ntensor([0., 0., 1., 1., 0., 0.])\ntensor([0., 1., 0., 0., 1., 0.])\ntensor([0., 1., 1., 1., 1., 0.])\ntensor([1., 0., 0., 0., 0., 1.])\ntensor([1., 0., 1., 1., 0., 1.])\ntensor([1., 1., 0., 0., 1., 1.])\ntensor([1., 1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "length = 64\n",
    "flag = 1\n",
    "y = torch.zeros((length, 1))\n",
    "for j in range(length):\n",
    "    for i in range(3):\n",
    "        if X[j][i] != X[j][5-i]:\n",
    "            flag = 0\n",
    "    if flag == 1:\n",
    "        y[j] = 1\n",
    "        print(X[j])\n",
    "    flag = 1\n",
    "\n",
    "y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(X, y)\n",
    "trainloader = DataLoader(train, batch_size=length, shuffle=False)\n",
    "epsilon = 0.1  # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_features =  6, out_features = 2, bias = True)\n",
    "        self.layer2 = torch.nn.Linear(in_features =  2, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.layer1(X)\n",
    "        out = torch.sigmoid(out)\n",
    "        out = self.layer2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "Training the model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "\n",
    "model = MLP()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom accuracy\n",
    "def accuracy(y_hat, y):\n",
    "    '''\n",
    "    y_hat is the model output - a Tensor of shape (n x num_classes)\n",
    "    y is the ground truth\n",
    "    '''\n",
    "    classes_prediction = y_hat.argmax(dim=1)\n",
    "    match_ground_truth = classes_prediction == y # tensor of booleans\n",
    "    correct_matches = match_ground_truth.sum()\n",
    "    return (correct_matches / y_hat.shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer, loss_meter, accuracy_meter):\n",
    "    for X, y in dataloader:\n",
    "        # 1. reset the gradients previously accumulated by the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # 2. get the predictions from the current state of the model\n",
    "        #    this is the forward pass\n",
    "        y_hat = model(X)\n",
    "        # 3. calculate the loss on the current mini-batch\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        # 4. execute the backward pass given the current loss\n",
    "        loss.backward()\n",
    "        # 5. update the value of the params\n",
    "        optimizer.step()\n",
    "        # 6. calculate the accuracy for this mini-batch\n",
    "        acc = accuracy(y_hat, y)\n",
    "        # 7. update the loss and accuracy AverageMeter\n",
    "        loss_meter.update(val=loss.item(), n=X.shape[0])\n",
    "        accuracy_meter.update(val=acc, n=X.shape[0])\n",
    "\n",
    "def train_model(model, dataloader, loss_fn, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        accuracy_meter = AverageMeter()\n",
    "        train_epoch(model, dataloader, loss_fn, optimizer, loss_meter, accuracy_meter)\n",
    "        print(f\"Epoch {epoch+1} completed. Loss - total: {loss_meter.sum} - average: {loss_meter.avg}; Accuracy: {accuracy_meter.avg}\")\n",
    "    return loss_meter.sum, accuracy_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "88072967529 - average: 0.10939668864011765; Accuracy: 56.0\n",
      "Epoch 802 completed. Loss - total: 7.001384258270264 - average: 0.10939662903547287; Accuracy: 56.0\n",
      "Epoch 803 completed. Loss - total: 7.001380920410156 - average: 0.10939657688140869; Accuracy: 56.0\n",
      "Epoch 804 completed. Loss - total: 7.001378059387207 - average: 0.10939653217792511; Accuracy: 56.0\n",
      "Epoch 805 completed. Loss - total: 7.001375198364258 - average: 0.10939648747444153; Accuracy: 56.0\n",
      "Epoch 806 completed. Loss - total: 7.001372337341309 - average: 0.10939644277095795; Accuracy: 56.0\n",
      "Epoch 807 completed. Loss - total: 7.001368999481201 - average: 0.10939639061689377; Accuracy: 56.0\n",
      "Epoch 808 completed. Loss - total: 7.00136661529541 - average: 0.10939635336399078; Accuracy: 56.0\n",
      "Epoch 809 completed. Loss - total: 7.001363277435303 - average: 0.1093963012099266; Accuracy: 56.0\n",
      "Epoch 810 completed. Loss - total: 7.001359939575195 - average: 0.10939624905586243; Accuracy: 56.0\n",
      "Epoch 811 completed. Loss - total: 7.001356601715088 - average: 0.10939619690179825; Accuracy: 56.0\n",
      "Epoch 812 completed. Loss - total: 7.001353740692139 - average: 0.10939615219831467; Accuracy: 56.0\n",
      "Epoch 813 completed. Loss - total: 7.001351356506348 - average: 0.10939611494541168; Accuracy: 56.0\n",
      "Epoch 814 completed. Loss - total: 7.00134801864624 - average: 0.1093960627913475; Accuracy: 56.0\n",
      "Epoch 815 completed. Loss - total: 7.001345634460449 - average: 0.10939602553844452; Accuracy: 56.0\n",
      "Epoch 816 completed. Loss - total: 7.0013427734375 - average: 0.10939598083496094; Accuracy: 56.0\n",
      "Epoch 817 completed. Loss - total: 7.001339912414551 - average: 0.10939593613147736; Accuracy: 56.0\n",
      "Epoch 818 completed. Loss - total: 7.001336574554443 - average: 0.10939588397741318; Accuracy: 56.0\n",
      "Epoch 819 completed. Loss - total: 7.001334190368652 - average: 0.10939584672451019; Accuracy: 56.0\n",
      "Epoch 820 completed. Loss - total: 7.001331329345703 - average: 0.10939580202102661; Accuracy: 56.0\n",
      "Epoch 821 completed. Loss - total: 7.001328468322754 - average: 0.10939575731754303; Accuracy: 56.0\n",
      "Epoch 822 completed. Loss - total: 7.001326084136963 - average: 0.10939572006464005; Accuracy: 56.0\n",
      "Epoch 823 completed. Loss - total: 7.001323699951172 - average: 0.10939568281173706; Accuracy: 56.0\n",
      "Epoch 824 completed. Loss - total: 7.001320838928223 - average: 0.10939563810825348; Accuracy: 56.0\n",
      "Epoch 825 completed. Loss - total: 7.001317501068115 - average: 0.1093955859541893; Accuracy: 56.0\n",
      "Epoch 826 completed. Loss - total: 7.001315116882324 - average: 0.10939554870128632; Accuracy: 56.0\n",
      "Epoch 827 completed. Loss - total: 7.001312255859375 - average: 0.10939550399780273; Accuracy: 56.0\n",
      "Epoch 828 completed. Loss - total: 7.001309871673584 - average: 0.10939546674489975; Accuracy: 56.0\n",
      "Epoch 829 completed. Loss - total: 7.001306533813477 - average: 0.10939541459083557; Accuracy: 56.0\n",
      "Epoch 830 completed. Loss - total: 7.001305103302002 - average: 0.10939539223909378; Accuracy: 56.0\n",
      "Epoch 831 completed. Loss - total: 7.001302242279053 - average: 0.1093953475356102; Accuracy: 56.0\n",
      "Epoch 832 completed. Loss - total: 7.001299858093262 - average: 0.10939531028270721; Accuracy: 56.0\n",
      "Epoch 833 completed. Loss - total: 7.0012969970703125 - average: 0.10939526557922363; Accuracy: 56.0\n",
      "Epoch 834 completed. Loss - total: 7.00129508972168 - average: 0.10939523577690125; Accuracy: 56.0\n",
      "Epoch 835 completed. Loss - total: 7.0012922286987305 - average: 0.10939519107341766; Accuracy: 56.0\n",
      "Epoch 836 completed. Loss - total: 7.001290321350098 - average: 0.10939516127109528; Accuracy: 56.0\n",
      "Epoch 837 completed. Loss - total: 7.001287460327148 - average: 0.1093951165676117; Accuracy: 56.0\n",
      "Epoch 838 completed. Loss - total: 7.001285076141357 - average: 0.10939507931470871; Accuracy: 56.0\n",
      "Epoch 839 completed. Loss - total: 7.001282691955566 - average: 0.10939504206180573; Accuracy: 56.0\n",
      "Epoch 840 completed. Loss - total: 7.001279830932617 - average: 0.10939499735832214; Accuracy: 56.0\n",
      "Epoch 841 completed. Loss - total: 7.001277923583984 - average: 0.10939496755599976; Accuracy: 56.0\n",
      "Epoch 842 completed. Loss - total: 7.001275062561035 - average: 0.10939492285251617; Accuracy: 56.0\n",
      "Epoch 843 completed. Loss - total: 7.0012736320495605 - average: 0.10939490050077438; Accuracy: 56.0\n",
      "Epoch 844 completed. Loss - total: 7.0012712478637695 - average: 0.1093948632478714; Accuracy: 56.0\n",
      "Epoch 845 completed. Loss - total: 7.0012688636779785 - average: 0.10939482599496841; Accuracy: 56.0\n",
      "Epoch 846 completed. Loss - total: 7.0012664794921875 - average: 0.10939478874206543; Accuracy: 56.0\n",
      "Epoch 847 completed. Loss - total: 7.001264572143555 - average: 0.10939475893974304; Accuracy: 56.0\n",
      "Epoch 848 completed. Loss - total: 7.0012617111206055 - average: 0.10939471423625946; Accuracy: 56.0\n",
      "Epoch 849 completed. Loss - total: 7.001259803771973 - average: 0.10939468443393707; Accuracy: 56.0\n",
      "Epoch 850 completed. Loss - total: 7.00125789642334 - average: 0.10939465463161469; Accuracy: 56.0\n",
      "Epoch 851 completed. Loss - total: 7.001255989074707 - average: 0.1093946248292923; Accuracy: 56.0\n",
      "Epoch 852 completed. Loss - total: 7.001253128051758 - average: 0.10939458012580872; Accuracy: 56.0\n",
      "Epoch 853 completed. Loss - total: 7.001251220703125 - average: 0.10939455032348633; Accuracy: 56.0\n",
      "Epoch 854 completed. Loss - total: 7.001249313354492 - average: 0.10939452052116394; Accuracy: 56.0\n",
      "Epoch 855 completed. Loss - total: 7.001246929168701 - average: 0.10939448326826096; Accuracy: 56.0\n",
      "Epoch 856 completed. Loss - total: 7.001245498657227 - average: 0.10939446091651917; Accuracy: 56.0\n",
      "Epoch 857 completed. Loss - total: 7.001242637634277 - average: 0.10939441621303558; Accuracy: 56.0\n",
      "Epoch 858 completed. Loss - total: 7.001240253448486 - average: 0.1093943789601326; Accuracy: 56.0\n",
      "Epoch 859 completed. Loss - total: 7.0012383460998535 - average: 0.10939434915781021; Accuracy: 56.0\n",
      "Epoch 860 completed. Loss - total: 7.001236438751221 - average: 0.10939431935548782; Accuracy: 56.0\n",
      "Epoch 861 completed. Loss - total: 7.001234531402588 - average: 0.10939428955316544; Accuracy: 56.0\n",
      "Epoch 862 completed. Loss - total: 7.001232624053955 - average: 0.10939425975084305; Accuracy: 56.0\n",
      "Epoch 863 completed. Loss - total: 7.001230716705322 - average: 0.10939422994852066; Accuracy: 56.0\n",
      "Epoch 864 completed. Loss - total: 7.001228332519531 - average: 0.10939419269561768; Accuracy: 56.0\n",
      "Epoch 865 completed. Loss - total: 7.001226425170898 - average: 0.10939416289329529; Accuracy: 56.0\n",
      "Epoch 866 completed. Loss - total: 7.001224517822266 - average: 0.1093941330909729; Accuracy: 56.0\n",
      "Epoch 867 completed. Loss - total: 7.001222610473633 - average: 0.10939410328865051; Accuracy: 56.0\n",
      "Epoch 868 completed. Loss - total: 7.001220703125 - average: 0.10939407348632812; Accuracy: 56.0\n",
      "Epoch 869 completed. Loss - total: 7.001218795776367 - average: 0.10939404368400574; Accuracy: 56.0\n",
      "Epoch 870 completed. Loss - total: 7.001217365264893 - average: 0.10939402133226395; Accuracy: 56.0\n",
      "Epoch 871 completed. Loss - total: 7.00121545791626 - average: 0.10939399152994156; Accuracy: 56.0\n",
      "Epoch 872 completed. Loss - total: 7.001213073730469 - average: 0.10939395427703857; Accuracy: 56.0\n",
      "Epoch 873 completed. Loss - total: 7.001211166381836 - average: 0.10939392447471619; Accuracy: 56.0\n",
      "Epoch 874 completed. Loss - total: 7.0012102127075195 - average: 0.10939390957355499; Accuracy: 56.0\n",
      "Epoch 875 completed. Loss - total: 7.001208305358887 - average: 0.1093938797712326; Accuracy: 56.0\n",
      "Epoch 876 completed. Loss - total: 7.001206398010254 - average: 0.10939384996891022; Accuracy: 56.0\n",
      "Epoch 877 completed. Loss - total: 7.001204490661621 - average: 0.10939382016658783; Accuracy: 56.0\n",
      "Epoch 878 completed. Loss - total: 7.001202583312988 - average: 0.10939379036426544; Accuracy: 56.0\n",
      "Epoch 879 completed. Loss - total: 7.0012006759643555 - average: 0.10939376056194305; Accuracy: 56.0\n",
      "Epoch 880 completed. Loss - total: 7.001198768615723 - average: 0.10939373075962067; Accuracy: 56.0\n",
      "Epoch 881 completed. Loss - total: 7.001197338104248 - average: 0.10939370840787888; Accuracy: 56.0\n",
      "Epoch 882 completed. Loss - total: 7.001195430755615 - average: 0.10939367860555649; Accuracy: 56.0\n",
      "Epoch 883 completed. Loss - total: 7.001194000244141 - average: 0.1093936562538147; Accuracy: 56.0\n",
      "Epoch 884 completed. Loss - total: 7.001192569732666 - average: 0.1093936339020729; Accuracy: 56.0\n",
      "Epoch 885 completed. Loss - total: 7.001190185546875 - average: 0.10939359664916992; Accuracy: 56.0\n",
      "Epoch 886 completed. Loss - total: 7.001188278198242 - average: 0.10939356684684753; Accuracy: 56.0\n",
      "Epoch 887 completed. Loss - total: 7.001186847686768 - average: 0.10939354449510574; Accuracy: 56.0\n",
      "Epoch 888 completed. Loss - total: 7.001185417175293 - average: 0.10939352214336395; Accuracy: 56.0\n",
      "Epoch 889 completed. Loss - total: 7.001184463500977 - average: 0.10939350724220276; Accuracy: 56.0\n",
      "Epoch 890 completed. Loss - total: 7.0011820793151855 - average: 0.10939346998929977; Accuracy: 56.0\n",
      "Epoch 891 completed. Loss - total: 7.001181125640869 - average: 0.10939345508813858; Accuracy: 56.0\n",
      "Epoch 892 completed. Loss - total: 7.001178741455078 - average: 0.1093934178352356; Accuracy: 56.0\n",
      "Epoch 893 completed. Loss - total: 7.0011773109436035 - average: 0.1093933954834938; Accuracy: 56.0\n",
      "Epoch 894 completed. Loss - total: 7.001176357269287 - average: 0.10939338058233261; Accuracy: 56.0\n",
      "Epoch 895 completed. Loss - total: 7.001173973083496 - average: 0.10939334332942963; Accuracy: 56.0\n",
      "Epoch 896 completed. Loss - total: 7.00117301940918 - average: 0.10939332842826843; Accuracy: 56.0\n",
      "Epoch 897 completed. Loss - total: 7.001171588897705 - average: 0.10939330607652664; Accuracy: 56.0\n",
      "Epoch 898 completed. Loss - total: 7.001169204711914 - average: 0.10939326882362366; Accuracy: 56.0\n",
      "Epoch 899 completed. Loss - total: 7.001168251037598 - average: 0.10939325392246246; Accuracy: 56.0\n",
      "Epoch 900 completed. Loss - total: 7.001166820526123 - average: 0.10939323157072067; Accuracy: 56.0\n",
      "Epoch 901 completed. Loss - total: 7.001165390014648 - average: 0.10939320921897888; Accuracy: 56.0\n",
      "Epoch 902 completed. Loss - total: 7.001163959503174 - average: 0.10939318686723709; Accuracy: 56.0\n",
      "Epoch 903 completed. Loss - total: 7.001162528991699 - average: 0.1093931645154953; Accuracy: 56.0\n",
      "Epoch 904 completed. Loss - total: 7.001160621643066 - average: 0.10939313471317291; Accuracy: 56.0\n",
      "Epoch 905 completed. Loss - total: 7.001160144805908 - average: 0.10939312726259232; Accuracy: 56.0\n",
      "Epoch 906 completed. Loss - total: 7.001158237457275 - average: 0.10939309746026993; Accuracy: 56.0\n",
      "Epoch 907 completed. Loss - total: 7.001156330108643 - average: 0.10939306765794754; Accuracy: 56.0\n",
      "Epoch 908 completed. Loss - total: 7.001155376434326 - average: 0.10939305275678635; Accuracy: 56.0\n",
      "Epoch 909 completed. Loss - total: 7.001153945922852 - average: 0.10939303040504456; Accuracy: 56.0\n",
      "Epoch 910 completed. Loss - total: 7.001152038574219 - average: 0.10939300060272217; Accuracy: 56.0\n",
      "Epoch 911 completed. Loss - total: 7.001151084899902 - average: 0.10939298570156097; Accuracy: 56.0\n",
      "Epoch 912 completed. Loss - total: 7.001149654388428 - average: 0.10939296334981918; Accuracy: 56.0\n",
      "Epoch 913 completed. Loss - total: 7.001148223876953 - average: 0.10939294099807739; Accuracy: 56.0\n",
      "Epoch 914 completed. Loss - total: 7.00114631652832 - average: 0.109392911195755; Accuracy: 56.0\n",
      "Epoch 915 completed. Loss - total: 7.001145362854004 - average: 0.10939289629459381; Accuracy: 56.0\n",
      "Epoch 916 completed. Loss - total: 7.0011444091796875 - average: 0.10939288139343262; Accuracy: 56.0\n",
      "Epoch 917 completed. Loss - total: 7.001142501831055 - average: 0.10939285159111023; Accuracy: 56.0\n",
      "Epoch 918 completed. Loss - total: 7.001140594482422 - average: 0.10939282178878784; Accuracy: 56.0\n",
      "Epoch 919 completed. Loss - total: 7.001140594482422 - average: 0.10939282178878784; Accuracy: 56.0\n",
      "Epoch 920 completed. Loss - total: 7.001138687133789 - average: 0.10939279198646545; Accuracy: 56.0\n",
      "Epoch 921 completed. Loss - total: 7.001137733459473 - average: 0.10939277708530426; Accuracy: 56.0\n",
      "Epoch 922 completed. Loss - total: 7.001136302947998 - average: 0.10939275473356247; Accuracy: 56.0\n",
      "Epoch 923 completed. Loss - total: 7.001134872436523 - average: 0.10939273238182068; Accuracy: 56.0\n",
      "Epoch 924 completed. Loss - total: 7.001133441925049 - average: 0.10939271003007889; Accuracy: 56.0\n",
      "Epoch 925 completed. Loss - total: 7.001132488250732 - average: 0.1093926951289177; Accuracy: 56.0\n",
      "Epoch 926 completed. Loss - total: 7.001131534576416 - average: 0.1093926802277565; Accuracy: 56.0\n",
      "Epoch 927 completed. Loss - total: 7.001129627227783 - average: 0.10939265042543411; Accuracy: 56.0\n",
      "Epoch 928 completed. Loss - total: 7.001129150390625 - average: 0.10939264297485352; Accuracy: 56.0\n",
      "Epoch 929 completed. Loss - total: 7.00112771987915 - average: 0.10939262062311172; Accuracy: 56.0\n",
      "Epoch 930 completed. Loss - total: 7.001126289367676 - average: 0.10939259827136993; Accuracy: 56.0\n",
      "Epoch 931 completed. Loss - total: 7.001125335693359 - average: 0.10939258337020874; Accuracy: 56.0\n",
      "Epoch 932 completed. Loss - total: 7.001123428344727 - average: 0.10939255356788635; Accuracy: 56.0\n",
      "Epoch 933 completed. Loss - total: 7.001122951507568 - average: 0.10939254611730576; Accuracy: 56.0\n",
      "Epoch 934 completed. Loss - total: 7.0011210441589355 - average: 0.10939251631498337; Accuracy: 56.0\n",
      "Epoch 935 completed. Loss - total: 7.001119613647461 - average: 0.10939249396324158; Accuracy: 56.0\n",
      "Epoch 936 completed. Loss - total: 7.001119613647461 - average: 0.10939249396324158; Accuracy: 56.0\n",
      "Epoch 937 completed. Loss - total: 7.001118183135986 - average: 0.10939247161149979; Accuracy: 56.0\n",
      "Epoch 938 completed. Loss - total: 7.001116752624512 - average: 0.109392449259758; Accuracy: 56.0\n",
      "Epoch 939 completed. Loss - total: 7.0011162757873535 - average: 0.1093924418091774; Accuracy: 56.0\n",
      "Epoch 940 completed. Loss - total: 7.001114845275879 - average: 0.10939241945743561; Accuracy: 56.0\n",
      "Epoch 941 completed. Loss - total: 7.001113414764404 - average: 0.10939239710569382; Accuracy: 56.0\n",
      "Epoch 942 completed. Loss - total: 7.00111198425293 - average: 0.10939237475395203; Accuracy: 56.0\n",
      "Epoch 943 completed. Loss - total: 7.001111030578613 - average: 0.10939235985279083; Accuracy: 56.0\n",
      "Epoch 944 completed. Loss - total: 7.001110076904297 - average: 0.10939234495162964; Accuracy: 56.0\n",
      "Epoch 945 completed. Loss - total: 7.001108646392822 - average: 0.10939232259988785; Accuracy: 56.0\n",
      "Epoch 946 completed. Loss - total: 7.001107215881348 - average: 0.10939230024814606; Accuracy: 56.0\n",
      "Epoch 947 completed. Loss - total: 7.001107215881348 - average: 0.10939230024814606; Accuracy: 56.0\n",
      "Epoch 948 completed. Loss - total: 7.001105308532715 - average: 0.10939227044582367; Accuracy: 56.0\n",
      "Epoch 949 completed. Loss - total: 7.001104354858398 - average: 0.10939225554466248; Accuracy: 56.0\n",
      "Epoch 950 completed. Loss - total: 7.001103401184082 - average: 0.10939224064350128; Accuracy: 56.0\n",
      "Epoch 951 completed. Loss - total: 7.001102447509766 - average: 0.10939222574234009; Accuracy: 56.0\n",
      "Epoch 952 completed. Loss - total: 7.001101970672607 - average: 0.10939221829175949; Accuracy: 56.0\n",
      "Epoch 953 completed. Loss - total: 7.001100540161133 - average: 0.1093921959400177; Accuracy: 56.0\n",
      "Epoch 954 completed. Loss - total: 7.001099109649658 - average: 0.10939217358827591; Accuracy: 56.0\n",
      "Epoch 955 completed. Loss - total: 7.0010986328125 - average: 0.10939216613769531; Accuracy: 56.0\n",
      "Epoch 956 completed. Loss - total: 7.001097679138184 - average: 0.10939215123653412; Accuracy: 56.0\n",
      "Epoch 957 completed. Loss - total: 7.001096248626709 - average: 0.10939212888479233; Accuracy: 56.0\n",
      "Epoch 958 completed. Loss - total: 7.001095294952393 - average: 0.10939211398363113; Accuracy: 56.0\n",
      "Epoch 959 completed. Loss - total: 7.001094818115234 - average: 0.10939210653305054; Accuracy: 56.0\n",
      "Epoch 960 completed. Loss - total: 7.00109338760376 - average: 0.10939208418130875; Accuracy: 56.0\n",
      "Epoch 961 completed. Loss - total: 7.001092433929443 - average: 0.10939206928014755; Accuracy: 56.0\n",
      "Epoch 962 completed. Loss - total: 7.001091480255127 - average: 0.10939205437898636; Accuracy: 56.0\n",
      "Epoch 963 completed. Loss - total: 7.001090049743652 - average: 0.10939203202724457; Accuracy: 56.0\n",
      "Epoch 964 completed. Loss - total: 7.001089572906494 - average: 0.10939202457666397; Accuracy: 56.0\n",
      "Epoch 965 completed. Loss - total: 7.001088619232178 - average: 0.10939200967550278; Accuracy: 56.0\n",
      "Epoch 966 completed. Loss - total: 7.001087188720703 - average: 0.10939198732376099; Accuracy: 56.0\n",
      "Epoch 967 completed. Loss - total: 7.001086711883545 - average: 0.10939197987318039; Accuracy: 56.0\n",
      "Epoch 968 completed. Loss - total: 7.001086235046387 - average: 0.10939197242259979; Accuracy: 56.0\n",
      "Epoch 969 completed. Loss - total: 7.001084327697754 - average: 0.1093919426202774; Accuracy: 56.0\n",
      "Epoch 970 completed. Loss - total: 7.001083850860596 - average: 0.10939193516969681; Accuracy: 56.0\n",
      "Epoch 971 completed. Loss - total: 7.001082897186279 - average: 0.10939192026853561; Accuracy: 56.0\n",
      "Epoch 972 completed. Loss - total: 7.001081943511963 - average: 0.10939190536737442; Accuracy: 56.0\n",
      "Epoch 973 completed. Loss - total: 7.0010809898376465 - average: 0.10939189046621323; Accuracy: 56.0\n",
      "Epoch 974 completed. Loss - total: 7.001079559326172 - average: 0.10939186811447144; Accuracy: 56.0\n",
      "Epoch 975 completed. Loss - total: 7.0010786056518555 - average: 0.10939185321331024; Accuracy: 56.0\n",
      "Epoch 976 completed. Loss - total: 7.001078128814697 - average: 0.10939184576272964; Accuracy: 56.0\n",
      "Epoch 977 completed. Loss - total: 7.001077175140381 - average: 0.10939183086156845; Accuracy: 56.0\n",
      "Epoch 978 completed. Loss - total: 7.0010762214660645 - average: 0.10939181596040726; Accuracy: 56.0\n",
      "Epoch 979 completed. Loss - total: 7.001075744628906 - average: 0.10939180850982666; Accuracy: 56.0\n",
      "Epoch 980 completed. Loss - total: 7.00107479095459 - average: 0.10939179360866547; Accuracy: 56.0\n",
      "Epoch 981 completed. Loss - total: 7.001074314117432 - average: 0.10939178615808487; Accuracy: 56.0\n",
      "Epoch 982 completed. Loss - total: 7.001073360443115 - average: 0.10939177125692368; Accuracy: 56.0\n",
      "Epoch 983 completed. Loss - total: 7.001071929931641 - average: 0.10939174890518188; Accuracy: 56.0\n",
      "Epoch 984 completed. Loss - total: 7.001070976257324 - average: 0.10939173400402069; Accuracy: 56.0\n",
      "Epoch 985 completed. Loss - total: 7.001070022583008 - average: 0.1093917191028595; Accuracy: 56.0\n",
      "Epoch 986 completed. Loss - total: 7.001070499420166 - average: 0.1093917265534401; Accuracy: 56.0\n",
      "Epoch 987 completed. Loss - total: 7.00106954574585 - average: 0.1093917116522789; Accuracy: 56.0\n",
      "Epoch 988 completed. Loss - total: 7.001068115234375 - average: 0.10939168930053711; Accuracy: 56.0\n",
      "Epoch 989 completed. Loss - total: 7.001067161560059 - average: 0.10939167439937592; Accuracy: 56.0\n",
      "Epoch 990 completed. Loss - total: 7.001065731048584 - average: 0.10939165204763412; Accuracy: 56.0\n",
      "Epoch 991 completed. Loss - total: 7.001065254211426 - average: 0.10939164459705353; Accuracy: 56.0\n",
      "Epoch 992 completed. Loss - total: 7.001065254211426 - average: 0.10939164459705353; Accuracy: 56.0\n",
      "Epoch 993 completed. Loss - total: 7.001063823699951 - average: 0.10939162224531174; Accuracy: 56.0\n",
      "Epoch 994 completed. Loss - total: 7.001063346862793 - average: 0.10939161479473114; Accuracy: 56.0\n",
      "Epoch 995 completed. Loss - total: 7.001061916351318 - average: 0.10939159244298935; Accuracy: 56.0\n",
      "Epoch 996 completed. Loss - total: 7.001061916351318 - average: 0.10939159244298935; Accuracy: 56.0\n",
      "Epoch 997 completed. Loss - total: 7.001060962677002 - average: 0.10939157754182816; Accuracy: 56.0\n",
      "Epoch 998 completed. Loss - total: 7.001060485839844 - average: 0.10939157009124756; Accuracy: 56.0\n",
      "Epoch 999 completed. Loss - total: 7.001059532165527 - average: 0.10939155519008636; Accuracy: 56.0\n",
      "Epoch 1000 completed. Loss - total: 7.001058101654053 - average: 0.10939153283834457; Accuracy: 56.0\n",
      "Training completed - final accuracy 56.0 and loss 7.001058101654053\n"
     ]
    }
   ],
   "source": [
    "loss, acc = train_model(model, trainloader, loss_fn, optimizer, num_epochs)\n",
    "print(f\"Training completed - final accuracy {acc} and loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[ 0.3007, -0.4176, -0.0744,  0.2343,  0.0907, -0.0131],\n",
       "                      [-0.2388,  0.1766, -0.0717,  0.4165,  0.2885, -0.2163]])),\n",
       "             ('layer1.bias', tensor([0.2537, 0.1453])),\n",
       "             ('layer2.weight', tensor([[-0.1945, -0.5203]])),\n",
       "             ('layer2.bias', tensor([-1.5240]))])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "model.state_dict()\n"
   ]
  }
 ]
}